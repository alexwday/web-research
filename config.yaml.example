# Deep Research Agent Configuration
# Copy this to config.yaml and customize

# =============================================================================
# LLM PROVIDER SETTINGS
# =============================================================================
llm:
  # Model selection by task type
  models:
    planner: "gpt-5-mini"
    researcher: "gpt-5-mini"
    writer: "gpt-5-mini"
    editor: "gpt-5-mini"
    discovery: "gpt-5-mini"

  # Token limits
  max_tokens:
    planner: 16000
    researcher: 16000
    writer: 16000
    editor: 16000
    discovery: 4000

  # Temperature settings (0.0 = deterministic, 1.0 = creative)
  temperature:
    planner: 0.3
    researcher: 0.2
    writer: 0.4
    editor: 0.2
    discovery: 0.2

# =============================================================================
# SEARCH & SCRAPING
# =============================================================================
search:
  # Search depth: "basic" or "advanced"
  depth: "advanced"

  # Max results per search
  max_results: 3

  # Search queries per task
  queries_per_task: 1

  # Include domains (optional, leave empty for all)
  include_domains: []

  # Exclude domains
  exclude_domains:
    - "pinterest.com"
    - "quora.com"

scraping:
  # Max content length per page (characters)
  max_content_length: 15000

  # Request timeout (seconds)
  timeout: 15

  # User agent rotation
  rotate_user_agents: true

# =============================================================================
# RESEARCH PARAMETERS
# =============================================================================
research:
  # Minimum tasks to generate in initial plan
  min_initial_tasks: 3

  # Maximum tasks (prevents infinite recursion)
  max_total_tasks: 5

  # Maximum recursion depth for sub-topics
  max_recursion_depth: 0

  # Minimum word count per section
  min_words_per_section: 100

  # Maximum word count per section
  max_words_per_section: 500

  # Required citations per section
  min_citations_per_section: 1

  # Enable recursive task discovery
  enable_recursion: false

  # Pause between research sessions (seconds)
  session_delay: 1

  # Maximum runtime (hours) - 0 for unlimited
  max_runtime_hours: 1

  # Maximum loops - 0 for unlimited
  max_loops: 5

# =============================================================================
# TASK DISCOVERY (gap analysis after sections are written)
# =============================================================================
discovery:
  # Enable/disable the discovery agent
  enabled: false

  # Run discovery every N completed tasks
  frequency: 3

  # Maximum new tasks to suggest per discovery run
  max_suggestions_per_run: 3

# =============================================================================
# EDITOR REWRITE PASS (cohesion editing before final compilation)
# =============================================================================
rewrite:
  # Enable/disable the editor rewrite pass
  enabled: false

# =============================================================================
# OUTPUT SETTINGS
# =============================================================================
output:
  # Output directory
  directory: "report"

  # Final report filename (without extension)
  report_name: "DEEP_RESEARCH_REPORT"

  # Export formats: ["markdown", "html", "pdf"]
  formats:
    - "markdown"
    - "html"

  # Include table of contents
  include_toc: true

  # Include bibliography
  include_bibliography: true

  # Include glossary
  include_glossary: true

  # Include executive summary
  include_summary: true

# =============================================================================
# QUALITY CONTROL
# =============================================================================
quality:
  # Minimum source quality score (0-1)
  min_source_quality: 0.5

# =============================================================================
# RATE LIMITING
# =============================================================================
rate_limits:
  # LLM API calls per minute
  llm_calls_per_minute: 20

  # Search API calls per minute
  search_calls_per_minute: 10

  # Web scraping requests per minute
  scrape_requests_per_minute: 30

# =============================================================================
# LOGGING & MONITORING
# =============================================================================
logging:
  # Log level: DEBUG, INFO, WARNING, ERROR
  level: "INFO"

  # Log to file
  file: "logs/research.log"

  # Log rotation (MB)
  max_file_size: 10

  # Keep N backup files
  backup_count: 5

  # Show progress in console
  show_progress: true

# =============================================================================
# DATABASE
# =============================================================================
database:
  # SQLite database file
  path: "research_state.db"

  # Enable WAL mode for better concurrency
  wal_mode: true
